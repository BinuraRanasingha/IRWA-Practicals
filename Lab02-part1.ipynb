{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa697da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Binura'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b773e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Binura\\IRWA\n"
     ]
    }
   ],
   "source": [
    "cd IRWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc8af442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def invertedIndex():\n",
    "    dictionary = dict()\n",
    "    directory = os.getcwd()+'/inverted'\n",
    "    #print(directory)\n",
    "    files = os.listdir(directory) \n",
    "    #print(files)\n",
    "    for file in files:\n",
    "        with open(os.getcwd()+'/inverted/'+file,'r') as f:\n",
    "            #print(f)\n",
    "            words = f.read().lower().split()\n",
    "            #print(words)\n",
    "\n",
    "            for word in words:\n",
    "                if word not in dictionary:\n",
    "                    dictionary[word] = [file]\n",
    "                else:\n",
    "                    dictionary[word].append(file)\n",
    "    return(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44869426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schizophrenia AND drug {'Doc1.txt', 'Doc2.txt'}\n",
      "for AND NOT(drug OR approach) {'Doc4.txt'}\n"
     ]
    }
   ],
   "source": [
    "#schizophrenia AND drug\n",
    "def And_op(list1,list2):\n",
    "    if((list1) and (list2)):\n",
    "        return set(list1).intersection(list2)\n",
    "    else:\n",
    "        return()\n",
    "    \n",
    "def OR_op(list1,list2):\n",
    "    return set(list1).union(list2) #definition of OR\n",
    "\n",
    "def Not_op(a):\n",
    "    directory = os.getcwd()+'/inverted' #current directory\n",
    "    filelist = os.listdir(directory) #files available in this directory\n",
    "    return set (filelist).symmetric_difference(a)\n",
    "    \n",
    "ii = invertedIndex()\n",
    "for key in ii:\n",
    "    if key == 'schizophrenia':\n",
    "        list1 = ii[key]\n",
    "        #print('list1',list1)\n",
    "    if key == 'drug':\n",
    "        list2 = ii[key]\n",
    "        #print('list2',list2)\n",
    "print('schizophrenia AND drug',And_op(list1,list2))\n",
    "\n",
    "#for AND NOT(drug OR approach)\n",
    "jj = invertedIndex()\n",
    "for key in jj:\n",
    "    if key == 'approach' : #dictionary terms\n",
    "        list3 = jj[key]\n",
    "        #print('list3',list3)\n",
    "    if key == 'drug':\n",
    "        list4 = jj[key]\n",
    "       #print('list4',list4)\n",
    "    if key == 'for':\n",
    "        list5 = jj[key]\n",
    "list6=OR_op(list3,list4)\n",
    "#print(list6)\n",
    "list7 = Not_op(list6)\n",
    "#print(list7)\n",
    "list8 = And_op(list5,list7)\n",
    "print('for AND NOT(drug OR approach)',list8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cc06f47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python', 'are', 'veri', 'intellig', 'and', 'work', 'veri', 'pythonli', 'and', 'now', 'they', 'are', 'python', 'their', 'way', 'to', 'success', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "sw = stopwords.words('english')\n",
    "#print(sw)\n",
    "#print(len(sw))\n",
    "\n",
    "quote = \"Pythoners are very intelligent and work very pythonly and now they are pythoning their way to success.\"\n",
    "\n",
    "tokenized_words = word_tokenize(quote)\n",
    "#print(tokenized_words)\n",
    "\n",
    "new_list_without_stop_words = []\n",
    "\n",
    "for tw in tokenized_words:\n",
    "    if tw not in sw:\n",
    "        new_list_without_stop_words.append(tw)\n",
    "#print(new_list_without_stop_words)\n",
    "\n",
    "#adding intelligent and work as new stopwords\n",
    "new_stop_word_list = ['intelligent','work']\n",
    "final_stop_word_list = sw + new_stop_word_list\n",
    "#print(final_stop_word_list)\n",
    "\n",
    "###stemming\n",
    "stemmed_word=[]\n",
    "stemmer = PorterStemmer()\n",
    "for i in tokenized_words:\n",
    "    stemmed_word.append(stemmer.stem(i))\n",
    "print(stemmed_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4ac899dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Binura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41179a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Binura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1d2dbbf1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [47]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m stemmer \u001b[38;5;241m=\u001b[39m PorterStemmer()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tokenized_words:\n\u001b[1;32m----> 6\u001b[0m     stemmed_word\u001b[38;5;241m.\u001b[39mappend(\u001b[43mstemmer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(stemmed_word)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\stem\\porter.py:658\u001b[0m, in \u001b[0;36mPorterStemmer.stem\u001b[1;34m(self, word, to_lowercase)\u001b[0m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstem\u001b[39m(\u001b[38;5;28mself\u001b[39m, word, to_lowercase\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    655\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;124;03m    :param to_lowercase: if `to_lowercase=True` the word always lowercase\u001b[39;00m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 658\u001b[0m     stem \u001b[38;5;241m=\u001b[39m \u001b[43mword\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m() \u001b[38;5;28;01mif\u001b[39;00m to_lowercase \u001b[38;5;28;01melse\u001b[39;00m word\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNLTK_EXTENSIONS \u001b[38;5;129;01mand\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool:\n\u001b[0;32m    661\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool[stem]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'lower'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb9b5fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
